{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taking Netflix By Storm: The Correlation between Watching and the Weather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-90-e84bec3e7f76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# load in netflix viewing data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utils'"
     ]
    }
   ],
   "source": [
    "# load in netflix viewing data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "viewing_df = pd.read_csv(\"netflix_viewing_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in weather data\n",
    "spokane_weather_df = pd.read_csv(\"spokane_temp_precip_data.csv\")\n",
    "\n",
    "#clean precipitation column\n",
    "precip_ser = spokane_weather_df[\"Precipitation\"]\n",
    "# if rain then 1, if not then 0\n",
    "for i in range (0, len(precip_ser)):\n",
    "    if precip_ser[i] > 0:\n",
    "        precip_ser.replace(precip_ser[i], 1, inplace=True)\n",
    "        \n",
    "# find median for future split\n",
    "temp_ser = spokane_weather_df[\"High\"]\n",
    "temp_ser.sort_values()\n",
    "temp_median = temp_ser.median()\n",
    "\n",
    "# add column to keep track of low/high\n",
    "temp_ser = spokane_weather_df[\"High\"] # get the unsorted series\n",
    "low_high_ser = pd.Series(dtype=int)\n",
    "for i in range (0, len(temp_ser)):\n",
    "    if temp_ser[i] < temp_median:\n",
    "        low_high_ser = low_high_ser.append(pd.Series(\"Low\"))\n",
    "    elif temp_ser[i] == temp_median or temp_ser[i] > temp_median:\n",
    "        low_high_ser = low_high_ser.append(pd.Series(\"High\"))\n",
    "        \n",
    "spokane_weather_df[\"Temp Category\"] = low_high_ser.values\n",
    "spokane_weather_df.to_csv(\"spokane_temp_precip_clean_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of low category 19.21212121212121\n",
      "Mean of high category 15.745098039215685\n",
      "\n",
      "Standard deviation of low category 17.50122206855207\n",
      "Standard deviation of high category 16.152824071666107\n"
     ]
    }
   ],
   "source": [
    "# join the two datasets together\n",
    "merged_netflix_weather_df = viewing_df.merge(spokane_weather_df, on=\"Date\")\n",
    "merged_netflix_weather_df.to_csv(\"merged_netflix_weather.csv\")\n",
    "\n",
    "# split the dataset\n",
    "low_temp_df = pd.DataFrame()\n",
    "high_temp_df = pd.DataFrame()\n",
    "grouped_by_temp_category = merged_netflix_weather_df.groupby(\"Temp Category\")\n",
    "for group_name, group_df in grouped_by_temp_category:\n",
    "    if group_name == \"Low\":\n",
    "        low_temp_df = group_df\n",
    "    elif group_name == \"High\":\n",
    "        high_temp_df = group_df\n",
    "\n",
    "# find mean viewing of both groups\n",
    "viewing_time_low_ser = low_temp_df[\"Length\"]\n",
    "viewing_time_high_ser = high_temp_df[\"Length\"]\n",
    "print(\"Mean of low category\", viewing_time_low_ser.mean())\n",
    "print(\"Mean of high category\", viewing_time_high_ser.mean())\n",
    "print()\n",
    "\n",
    "# find the standard deviation of each group\n",
    "print(\"Standard deviation of low category\", viewing_time_low_ser.std())\n",
    "print(\"Standard deviation of high category\", viewing_time_high_ser.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low temp confidence interval: (14.903618175364258, 23.520624248878164)\n",
      "High temp confidence interval: (11.22140246954323, 20.26879360888814)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\n\\nXbar = 37.56 # S1 mean\\nXbar2 = 51.16 # S2 mean\\n\\nconf_interval = (30.409021860920006, 44.71097813908) # S1 confidence interval\\nconf_interval2 = (37.666069540063575, 64.65393045993642) # S2 confidence interval\\n\\n\\n## graph them\\nplt.title(\"S1 and S2 Confidence Intervals\")\\n\\nplt.plot([.8, .8], conf_interval, marker=\"_\", color=\"blue\")\\nplt.plot([.8], [Xbar], marker=\"o\", color=\"blue\", label=\"S1\")\\n\\nplt.plot([1.2, 1.2], conf_interval2, marker=\"_\", color=\"red\")\\nplt.plot([1.2], [Xbar2], marker=\"o\", color=\"red\", label=\"S2\")\\n\\n#set x and y limits\\nplt.ylim([0, 70])\\nplt.xlim([0.5, 1.5])\\nplt.legend()\\n'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the Confidence Interval at 97.5%\n",
    "#low weather \n",
    "Xbar_low = viewing_time_low_ser.mean()\n",
    "std_low = viewing_time_low_ser.std()\n",
    "n = len(viewing_time_low_ser)\n",
    "t = 2.000\n",
    "margin_of_error = t * std_low / np.sqrt(n)\n",
    "conf_interval_low_temp = (Xbar_low - margin_of_error, Xbar_low + margin_of_error)\n",
    "print(\"Low temp confidence interval:\", conf_interval_low_temp)\n",
    "\n",
    "#high weather \n",
    "Xbar_high = viewing_time_high_ser.mean()\n",
    "std_high = viewing_time_high_ser.std()\n",
    "n = len(viewing_time_high_ser)\n",
    "t = 2.000\n",
    "margin_of_error = t * std_high / np.sqrt(n)\n",
    "conf_interval_low_temp = (Xbar_high - margin_of_error, Xbar_high + margin_of_error)\n",
    "print(\"High temp confidence interval:\", conf_interval_low_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "Xbar = 37.56 # S1 mean\n",
    "Xbar2 = 51.16 # S2 mean\n",
    "\n",
    "conf_interval = (30.409021860920006, 44.71097813908) # S1 confidence interval\n",
    "conf_interval2 = (37.666069540063575, 64.65393045993642) # S2 confidence interval\n",
    "\n",
    "\n",
    "## graph them\n",
    "plt.title(\"S1 and S2 Confidence Intervals\")\n",
    "\n",
    "plt.plot([.8, .8], conf_interval, marker=\"_\", color=\"blue\")\n",
    "plt.plot([.8], [Xbar], marker=\"o\", color=\"blue\", label=\"S1\")\n",
    "\n",
    "plt.plot([1.2, 1.2], conf_interval2, marker=\"_\", color=\"red\")\n",
    "plt.plot([1.2], [Xbar2], marker=\"o\", color=\"red\", label=\"S2\")\n",
    "\n",
    "#set x and y limits\n",
    "plt.ylim([0, 70])\n",
    "plt.xlim([0.5, 1.5])\n",
    "plt.legend()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "* find standard deviation of each (Thursday)\n",
    "    * graph those standard deviations (Thursday)\n",
    "* create a hypothesis for testing(Go through all 5 steps) (Sunday)\n",
    "* write an introduction/commentary throughout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
